{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TSB_UAD.models.distance import Fourier\n",
    "from TSB_UAD.models.feature import Window\n",
    "from TSB_UAD.utils.slidingWindows import find_length, plotFig, printResult\n",
    "\n",
    "from TSB_UAD.models.iforest import IForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Isolation Forest***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Data Pre-Processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the following time-series:\n",
    "\n",
    "- ECG1\n",
    "- ECG1_20k\n",
    "- IOPS1\n",
    "- SMD1\n",
    "- Occupancy1\n",
    "- ECG1+IOPS1\n",
    "- SMD1+Occupancy1\n",
    "- ECG1+IOPS1+Occupancy1\n",
    "- SMD1+ECG1+Occupancy1\n",
    "- ECG1+IOPS1+SMD1+Occupancy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for the evaluation.\n",
    "all_data = []\n",
    "\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "all_data.extend(data['evaluation']['single_normality'])\n",
    "all_data.extend(data['evaluation']['double_normality'])\n",
    "all_data.extend(data['evaluation']['triple_normality'])\n",
    "all_data.extend(data['evaluation']['quadruple_normality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Pre-processing for non-streaming***\n",
    "Simple data pre-processing based on TSB-UAD. This pre-processing serves as the pre-processing baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Series name: ECG1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: ECG1_20k\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: IOPS1\n",
      "Estimated Subsequence length:  288\n",
      "\n",
      "Time-Series name: SMD1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: SMD1+Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1+Occupancy1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: SMD1+ECG1+Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1+SMD1+Occupancy1\n",
      "Estimated Subsequence length:  100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for filename, info in loaded_dict.items():\n",
    "for timeseries in all_data:\n",
    "    #ts_filepath = f\"TS-Data-Files/{filename}\"\n",
    "    #ts = pd.read_csv(ts_filepath, header=None).dropna().to_numpy()\n",
    "\n",
    "    #name = ts_filepath.split('/')[-1]\n",
    "    #max_length = ts.shape[0]\n",
    "    #data = ts[:max_length, 0].astype(float)\n",
    "    #label = ts[:max_length, 1]\n",
    "\n",
    "    name = timeseries['Name']\n",
    "    data = timeseries['data']\n",
    "    max_length = data.shape[0]\n",
    "    label = timeseries['labels']\n",
    "\n",
    "    slidingWindow = find_length(data)\n",
    "    X_data = Window(window=slidingWindow).convert(data).to_numpy()\n",
    "\n",
    "    print(f'Time-Series name: {name}')\n",
    "    print(\"Estimated Subsequence length: \", slidingWindow)\n",
    "    print()\n",
    "    \n",
    "    preprocessed_dict[name] = {\n",
    "        'name': name,\n",
    "        'data': data,\n",
    "        'label': label,\n",
    "        'slidingWindow': slidingWindow,\n",
    "        'X_data': X_data,\n",
    "        'Time series length': len(data),\n",
    "        'Number of abnormal points': list(label).count(1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Pre-processing for both naive streaming variant and streaming variant with batch history***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Series name: ECG1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: ECG1_20k\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: IOPS1\n",
      "Estimated Subsequence length:  288\n",
      "\n",
      "Time-Series name: SMD1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: SMD1+Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1+Occupancy1\n",
      "Estimated Subsequence length:  100\n",
      "\n",
      "Time-Series name: SMD1+ECG1+Occupancy1\n",
      "Estimated Subsequence length:  125\n",
      "\n",
      "Time-Series name: ECG1+IOPS1+SMD1+Occupancy1\n",
      "Estimated Subsequence length:  100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the number of windows to be fit per batch.\n",
    "windows_per_batch = 150\n",
    "\n",
    "for timeseries in all_data:\n",
    "    name = timeseries['Name']\n",
    "\n",
    "    data = timeseries['data']\n",
    "    max_length = data.shape[0]\n",
    "    label = timeseries['labels']\n",
    "\n",
    "    slidingWindow = find_length(data)\n",
    "    X_data = Window(window=slidingWindow).convert(data).to_numpy()\n",
    "\n",
    "    # Take the series and batch it.\n",
    "    batched_data = []\n",
    "\n",
    "    i = 0\n",
    "    flag = True\n",
    "    # Keep taking batches until the point at which no new windows can be taken.\n",
    "    while i < len(data) and flag:\n",
    "        # The data batches begin at the index indicated. If first batch, then the beginning of the time series.\n",
    "        batch_samples_begin = i\n",
    "\n",
    "        # The data batches end at the index where `windows_per_batch` can be *completely* extracted since the batch beginning. \n",
    "        # Formula: \n",
    "        #   i: current beginning of batch / offset\n",
    "        #   + slidingWindow: to have enough samples extract one window\n",
    "        #   + windows_per_batch: to have enough samples to extract the rest of the windows\n",
    "        #   - 1: because the first window extracted is counted twice\n",
    "        batch_samples_end = i + windows_per_batch + slidingWindow - 1\n",
    "        \n",
    "        # Guard against the ending of the time series where a full batch cannot be formed.\n",
    "        if batch_samples_end > len(data):\n",
    "            batch_samples_end = len(data)\n",
    "            flag = False\n",
    " \n",
    "        # Guard against case where the batch cannot hold even one window.\n",
    "        if len(data[batch_samples_begin:batch_samples_end]) < slidingWindow:\n",
    "            break\n",
    "\n",
    "        batched_data.append(data[batch_samples_begin:batch_samples_end])\n",
    "\n",
    "        # The next batch starts at the point where a new window be created after the last window of the last batch.\n",
    "        # So, end of the previous window - length of window = start of the last window.\n",
    "        #   start of the last window + 1 = start of the first window of the next batch.\n",
    "        i = batch_samples_end - slidingWindow + 1\n",
    "\n",
    "    # Take the windows and batch them.\n",
    "    batched_X_data = []\n",
    "    i = 0\n",
    "    while i < len(X_data):\n",
    "        begin = i\n",
    "        end = i + windows_per_batch\n",
    "        if end > len(X_data):\n",
    "            end = len(X_data)\n",
    "\n",
    "        batched_X_data.append(X_data[begin:end])\n",
    "        i += windows_per_batch\n",
    "\n",
    "    print(f'Time-Series name: {name}')\n",
    "    print(\"Estimated Subsequence length: \", slidingWindow)\n",
    "    print()\n",
    "    \n",
    "    # Store the pre-processed variables in the new dictionary\n",
    "    preprocessed_dict[name] = {\n",
    "        'name': name,\n",
    "        'data': data,\n",
    "        'label': label,\n",
    "        'slidingWindow': slidingWindow,\n",
    "        'X_data': X_data,\n",
    "        'batched_X_data': batched_X_data,\n",
    "        'batched_data': batched_data,\n",
    "        'Time series length': len(data),\n",
    "        'Number of abnormal points': list(label).count(1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Pre-processing for streaming variant with dynamic partitioning (change point detection)***\n",
    "Naively partitioning the data is not a reliable solution. We want to partition the data as soon as an abrupt change occurs. For that, we can use:\n",
    "- 1. MinMax range partitioning\n",
    "- 2. Percentile Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***MinMax range partitioning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filename, info in loaded_dict.items():\n",
    "for timeseries in all_data:\n",
    "    #ts_filepath = f\"TS-Data-Files/{filename}\"\n",
    "    #ts = pd.read_csv(ts_filepath, header=None).dropna().to_numpy()\n",
    "\n",
    "    #name = ts_filepath.split('/')[-1]\n",
    "    #max_length = ts.shape[0]\n",
    "    #data = ts[:max_length, 0].astype(float)\n",
    "    #label = ts[:max_length, 1]\n",
    "\n",
    "    name = timeseries['Name']\n",
    "    data = timeseries['data']\n",
    "    max_length = data.shape[0]\n",
    "    label = timeseries['labels']\n",
    "    global_sw = find_length(data)\n",
    "\n",
    "    initial_partition_length = 500\n",
    "    initial_partition = data[:initial_partition_length]\n",
    "\n",
    "    max = np.max(initial_partition)\n",
    "    min = np.min(initial_partition)\n",
    "\n",
    "    data_partitions = [initial_partition]\n",
    "    current_partition = []\n",
    "    change_detected = False\n",
    "\n",
    "    p = 500\n",
    "    change_point_threshold = 0.8\n",
    "    exceed_threshold = 0.5\n",
    "    post_change_points = []\n",
    "\n",
    "    for point in data[len(initial_partition):]:\n",
    "        \n",
    "        # Check for significant change\n",
    "        if (point > max * (1 + change_point_threshold)) or (point < min * (1 - change_point_threshold)):\n",
    "            change_detected = True\n",
    "     \n",
    "        current_partition.append(point)\n",
    "\n",
    "\n",
    "        # After change, collect additional points\n",
    "        if change_detected:\n",
    "            post_change_points.append(point)\n",
    "            if len(post_change_points) == p:\n",
    "                exceeds_threshold_points = [(pt > max * (1 + change_point_threshold) or pt < min * (1 - change_point_threshold)) for pt in post_change_points]\n",
    "                if sum(exceeds_threshold_points) >= exceed_threshold * p:\n",
    "                    max = np.mean([max] + [pt for pt in post_change_points if pt > max])\n",
    "                    min = np.mean([min] + [pt for pt in post_change_points if pt < min])\n",
    "\n",
    "                post_change_points = []\n",
    "\n",
    "                # Add the current partition to data partitions\n",
    "                data_partitions.append(np.array(current_partition))\n",
    "                current_partition = []\n",
    "                change_detected = False\n",
    "                \n",
    "        \n",
    "    # Add any remaining points in current_partition to data_partitions\n",
    "    if current_partition:\n",
    "        data_partitions.append(np.array(current_partition))\n",
    "\n",
    "    \n",
    "    preprocessed_dict[name] = {\n",
    "        'name': name,\n",
    "        'data': data,\n",
    "        'label': label,\n",
    "        'data partitions': data_partitions,\n",
    "        'global_sliding_window': global_sw,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the number of partitions created for each time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 420 for file: ECG1\n",
      "Number of partitions: 38 for file: ECG1_20k\n",
      "Number of partitions: 3 for file: IOPS1\n",
      "Number of partitions: 24 for file: SMD1\n",
      "Number of partitions: 2 for file: Occupancy1\n",
      "Number of partitions: 39 for file: ECG1+IOPS1\n",
      "Number of partitions: 25 for file: SMD1+Occupancy1\n",
      "Number of partitions: 40 for file: ECG1+IOPS1+Occupancy1\n",
      "Number of partitions: 64 for file: SMD1+ECG1+Occupancy1\n",
      "Number of partitions: 40 for file: ECG1+IOPS1+SMD1+Occupancy1\n"
     ]
    }
   ],
   "source": [
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "\n",
    "    print(f\"Number of partitions: {len(ts['data partitions'])} for file: {ts['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the size of the partitions consistent with the initial size of the time-series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of partitions: 229900 for file: ECG1. Original data size: 229900\n",
      "Total size of partitions: 20000 for file: ECG1_20k. Original data size: 20000\n",
      "Total size of partitions: 8784 for file: IOPS1. Original data size: 8784\n",
      "Total size of partitions: 28479 for file: SMD1. Original data size: 28479\n",
      "Total size of partitions: 2665 for file: Occupancy1. Original data size: 2665\n",
      "Total size of partitions: 28784 for file: ECG1+IOPS1. Original data size: 28784\n",
      "Total size of partitions: 31144 for file: SMD1+Occupancy1. Original data size: 31144\n",
      "Total size of partitions: 31449 for file: ECG1+IOPS1+Occupancy1. Original data size: 31449\n",
      "Total size of partitions: 51144 for file: SMD1+ECG1+Occupancy1. Original data size: 51144\n",
      "Total size of partitions: 59928 for file: ECG1+IOPS1+SMD1+Occupancy1. Original data size: 59928\n"
     ]
    }
   ],
   "source": [
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    par_size = 0\n",
    "    for partition in ts['data partitions']:\n",
    "        par_size += len(partition)\n",
    "    \n",
    "    print(f\"Total size of partitions: {par_size} for file: {ts['name']}. Original data size: {len(ts['data'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "\n",
    "    if len(ts['data partitions']) < 10:\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(ts['data partitions']), figsize=(20, 5))\n",
    "\n",
    "        for i, array in enumerate(ts['data partitions']):\n",
    "            axes[i].plot(array)\n",
    "            axes[i].set_title(f\"Partition {i+1} of {ts['name']}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Percentile Partitioning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filename, info in loaded_dict.items():\n",
    "for timeseries in all_data:\n",
    "    #ts_filepath = f\"TS-Data-Files/{filename}\"\n",
    "    #ts = pd.read_csv(ts_filepath, header=None).dropna().to_numpy()\n",
    "\n",
    "    #name = ts_filepath.split('/')[-1]\n",
    "    #max_length = ts.shape[0]\n",
    "    #data = ts[:max_length, 0].astype(float)\n",
    "    #label = ts[:max_length, 1]\n",
    "\n",
    "    name = timeseries['Name']\n",
    "    data = timeseries['data']\n",
    "    max_length = data.shape[0]\n",
    "    label = timeseries['labels']\n",
    "    global_sw = find_length(data)\n",
    "\n",
    "\n",
    "    # Filter the normal points (label == 0)\n",
    "    #normal_indices = [i for i, lbl in enumerate(label) if lbl == 0]\n",
    "    #normal_data = data[normal_indices]\n",
    "\n",
    "    #normal_data_par_length = int(len(normal_data) * 0.10)\n",
    "    #normal_data = normal_data[:normal_data_par_length]\n",
    "\n",
    "    initial_partition_length = 500\n",
    "    initial_partition = data[:initial_partition_length]\n",
    "\n",
    "    # Compute initial percentiles\n",
    "    percentile_5 = np.percentile(initial_partition, 5)\n",
    "    percentile_95 = np.percentile(initial_partition, 95)\n",
    "\n",
    "    data_partitions = [initial_partition]\n",
    "    current_partition = []\n",
    "    change_detected = False\n",
    "    p = 500\n",
    "    exceed_threshold = 0.5\n",
    "    post_change_points = []\n",
    "\n",
    "    for point in data[initial_partition_length:]:\n",
    "        \n",
    "        # Check for significant change\n",
    "        if (point < percentile_5) or (point > percentile_95):\n",
    "            change_detected = True\n",
    "     \n",
    "        current_partition.append(point)\n",
    "\n",
    "\n",
    "        # After change, collect additional points\n",
    "        if change_detected:\n",
    "            post_change_points.append(point)\n",
    "            if len(post_change_points) == p:\n",
    "                exceeds_threshold_points = [(pt < percentile_5 or pt > percentile_95) for pt in post_change_points]\n",
    "                if sum(exceeds_threshold_points) / p >= exceed_threshold:\n",
    "                    # Update percentiles\n",
    "                    percentile_5 = np.percentile(post_change_points, 5)\n",
    "                    percentile_95 = np.percentile(post_change_points, 95)\n",
    "\n",
    "                post_change_points = []\n",
    "                # Add the current partition to data partitions\n",
    "                data_partitions.append(np.array(current_partition))\n",
    "                current_partition = []\n",
    "                change_detected = False\n",
    "                \n",
    "        \n",
    "    # Add any remaining points in current_partition to data_partitions\n",
    "    if current_partition:\n",
    "        data_partitions.append(np.array(current_partition))\n",
    "\n",
    "    \n",
    "    preprocessed_dict[name] = {\n",
    "        'name': name,\n",
    "        'data': data,\n",
    "        'label': label,\n",
    "        'data partitions': data_partitions,\n",
    "        'global_sliding_window': global_sw,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 433 for file: ECG1\n",
      "Number of partitions: 39 for file: ECG1_20k\n",
      "Number of partitions: 17 for file: IOPS1\n",
      "Number of partitions: 46 for file: SMD1\n",
      "Number of partitions: 4 for file: Occupancy1\n",
      "Number of partitions: 55 for file: ECG1+IOPS1\n",
      "Number of partitions: 51 for file: SMD1+Occupancy1\n",
      "Number of partitions: 58 for file: ECG1+IOPS1+Occupancy1\n",
      "Number of partitions: 86 for file: SMD1+ECG1+Occupancy1\n",
      "Number of partitions: 107 for file: ECG1+IOPS1+SMD1+Occupancy1\n"
     ]
    }
   ],
   "source": [
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "\n",
    "    print(f\"Number of partitions: {len(ts['data partitions'])} for file: {ts['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of partitions: 229900 for file: ECG1. Original data size: 229900\n",
      "Total size of partitions: 20000 for file: ECG1_20k. Original data size: 20000\n",
      "Total size of partitions: 8784 for file: IOPS1. Original data size: 8784\n",
      "Total size of partitions: 28479 for file: SMD1. Original data size: 28479\n",
      "Total size of partitions: 2665 for file: Occupancy1. Original data size: 2665\n",
      "Total size of partitions: 28784 for file: ECG1+IOPS1. Original data size: 28784\n",
      "Total size of partitions: 31144 for file: SMD1+Occupancy1. Original data size: 31144\n",
      "Total size of partitions: 31449 for file: ECG1+IOPS1+Occupancy1. Original data size: 31449\n",
      "Total size of partitions: 51144 for file: SMD1+ECG1+Occupancy1. Original data size: 51144\n",
      "Total size of partitions: 59928 for file: ECG1+IOPS1+SMD1+Occupancy1. Original data size: 59928\n"
     ]
    }
   ],
   "source": [
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    par_size = 0\n",
    "    for partition in ts['data partitions']:\n",
    "        par_size += len(partition)\n",
    "    \n",
    "    print(f\"Total size of partitions: {par_size} for file: {ts['name']}. Original data size: {len(ts['data'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Plot TS length and number of abnormal points***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames, time series lengths, and number of abnormal points\n",
    "filenames = list(preprocessed_dict.keys())\n",
    "time_series_lengths = [data['Time series length'] for data in preprocessed_dict.values()]\n",
    "number_of_abnormal_points = [data['Number of abnormal points'] for data in preprocessed_dict.values()]\n",
    "\n",
    "# Plot 'Time series length' and 'Number of abnormal points' for each filename\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(filenames, time_series_lengths, marker='o', linestyle='-', color='skyblue')\n",
    "plt.xlabel('Filename')\n",
    "plt.ylabel('Time series length')\n",
    "plt.title('Time Series Length for Each Filename')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(filenames, number_of_abnormal_points, marker='o', linestyle='-', color='lightgreen')\n",
    "plt.xlabel('Filename')\n",
    "plt.ylabel('Number of abnormal points')\n",
    "plt.title('Number of Abnormal Points for Each Filename')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Anomaly Detection***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Information:\n",
    "- TN: The point is normal and we predicted it is normal\n",
    "- TP: The point is abnormal and we predicted it is abnormal\n",
    "- FP: The point is normal and we predicted it is abnormal\n",
    "- FN: The point is abnormal and we predicted it is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = ['AUC', \n",
    "                'Precision', \n",
    "                'Recall', \n",
    "                'F', \n",
    "                'Rrecall', \n",
    "                'ExistenceReward',\n",
    "                'OverlapReward',\n",
    "                'Rprecision',\n",
    "                'Rf',\n",
    "                'Precision@k',\n",
    "                'R_AUC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to colorize the cells of the dataframe results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_diff(val):\n",
    "    color = ''\n",
    "    if val > 0:\n",
    "        color = 'background-color: lightgreen'\n",
    "    elif val < 0:\n",
    "        color = 'background-color: lightcoral'\n",
    "    return color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Isolation Forest***(Original)\n",
    "Non-Streaming Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'IForest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    x = ts['X_data']\n",
    "    clf = IForest(n_jobs=7, random_state=42)\n",
    "\n",
    "    t0 = time()\n",
    "    clf.fit(x)\n",
    "    \n",
    "    score = clf.decision_scores_\n",
    "    score = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\n",
    "    score = np.array([score[0]]*math.ceil((ts['slidingWindow']-1)/2) + list(score) + [score[-1]]*((ts['slidingWindow']-1)//2))\n",
    "\n",
    "    t1 = time()\n",
    "    \n",
    "    # Plot figure\n",
    "    #plotFig(ts['data'], ts['label'], score, ts['slidingWindow'], fileName=ts['name'] + ' ' + loaded_dict[ts['name']][0], modelName=modelName)\n",
    "\n",
    "    # Calculate the results\n",
    "    L = printResult(ts['data'], ts['label'], score, ts['slidingWindow'], ts['name'], modelName)\n",
    "    #L = [ '%.2f' % elem for elem in L]\n",
    "    #results.append([filename] + L)\n",
    "    results.append([filename] + L + [t1-t0, len(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['Filename'] + eval_metrics\n",
    "columns = ['Name'] + ['AUC', 'Precision', 'Recall', 'F-score', 'Range-recall', 'ExistenceReward', 'OverlapReward', 'Range-precision', 'Range-Fscore', 'Precision@k', 'RangeAUC', 'Time', 'Number of Windows']\n",
    "iforest_res = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Time</th>\n",
       "      <th>Number of Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG1</td>\n",
       "      <td>0.963406</td>\n",
       "      <td>0.208339</td>\n",
       "      <td>29.021253</td>\n",
       "      <td>229801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG1_20k</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.669630</td>\n",
       "      <td>2.212659</td>\n",
       "      <td>19901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOPS1</td>\n",
       "      <td>0.534240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.413100</td>\n",
       "      <td>8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMD1</td>\n",
       "      <td>0.845381</td>\n",
       "      <td>0.306236</td>\n",
       "      <td>3.977942</td>\n",
       "      <td>28355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occupancy1</td>\n",
       "      <td>0.871266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335934</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECG1+IOPS1</td>\n",
       "      <td>0.809130</td>\n",
       "      <td>0.533485</td>\n",
       "      <td>3.239372</td>\n",
       "      <td>28685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMD1+Occupancy1</td>\n",
       "      <td>0.833035</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>4.365139</td>\n",
       "      <td>31020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECG1+IOPS1+Occupancy1</td>\n",
       "      <td>0.882892</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>3.524515</td>\n",
       "      <td>31350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMD1+ECG1+Occupancy1</td>\n",
       "      <td>0.688620</td>\n",
       "      <td>0.223912</td>\n",
       "      <td>7.099129</td>\n",
       "      <td>51020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECG1+IOPS1+SMD1+Occupancy1</td>\n",
       "      <td>0.651722</td>\n",
       "      <td>0.213767</td>\n",
       "      <td>6.819192</td>\n",
       "      <td>59829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name       AUC  Precision@k       Time  \\\n",
       "0                        ECG1  0.963406     0.208339  29.021253   \n",
       "1                    ECG1_20k  0.973288     0.669630   2.212659   \n",
       "2                       IOPS1  0.534240     0.000000   2.413100   \n",
       "3                        SMD1  0.845381     0.306236   3.977942   \n",
       "4                  Occupancy1  0.871266     0.000000   0.335934   \n",
       "5                  ECG1+IOPS1  0.809130     0.533485   3.239372   \n",
       "6             SMD1+Occupancy1  0.833035     0.223404   4.365139   \n",
       "7       ECG1+IOPS1+Occupancy1  0.882892     0.462493   3.524515   \n",
       "8        SMD1+ECG1+Occupancy1  0.688620     0.223912   7.099129   \n",
       "9  ECG1+IOPS1+SMD1+Occupancy1  0.651722     0.213767   6.819192   \n",
       "\n",
       "   Number of Windows  \n",
       "0             229801  \n",
       "1              19901  \n",
       "2               8497  \n",
       "3              28355  \n",
       "4               2541  \n",
       "5              28685  \n",
       "6              31020  \n",
       "7              31350  \n",
       "8              51020  \n",
       "9              59829  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_res['Number of anomalies'] = iforest_res['Name'].apply(lambda x: np.sum(preprocessed_dict[x]['label']))\n",
    "iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "                      Name &      AUC &  Precision@k &      Time &  Number of Windows \\\\\n",
      "\\midrule\n",
      "                      ECG1 & 0.963406 &     0.208339 & 29.021253 &             229801 \\\\\n",
      "                  ECG1\\_20k & 0.973288 &     0.669630 &  2.212659 &              19901 \\\\\n",
      "                     IOPS1 & 0.534240 &     0.000000 &  2.413100 &               8497 \\\\\n",
      "                      SMD1 & 0.845381 &     0.306236 &  3.977942 &              28355 \\\\\n",
      "                Occupancy1 & 0.871266 &     0.000000 &  0.335934 &               2541 \\\\\n",
      "                ECG1+IOPS1 & 0.809130 &     0.533485 &  3.239372 &              28685 \\\\\n",
      "           SMD1+Occupancy1 & 0.833035 &     0.223404 &  4.365139 &              31020 \\\\\n",
      "     ECG1+IOPS1+Occupancy1 & 0.882892 &     0.462493 &  3.524515 &              31350 \\\\\n",
      "      SMD1+ECG1+Occupancy1 & 0.688620 &     0.223912 &  7.099129 &              51020 \\\\\n",
      "ECG1+IOPS1+SMD1+Occupancy1 & 0.651722 &     0.213767 &  6.819192 &              59829 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_res.to_csv('Results/Isolation-Forest/IForest_Non-Streaming.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Isolation Forest***(Variant 1)\n",
    "Naive Streaming Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'IForest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    clf = IForest(n_jobs=7, random_state=42)\n",
    "    x = ts['X_data']\n",
    "    total_time = 0\n",
    "\n",
    "    score = []\n",
    "    #for par in range(n):\n",
    "    for batch in ts['batched_X_data']:\n",
    "\n",
    "        t0 = time()\n",
    "        if len(batch) == 1:\n",
    "            score.append(score[-1])\n",
    "        else:\n",
    "            clf.fit(batch)\n",
    "            score.extend(clf.decision_scores_)\n",
    "            t1 = time()\n",
    "\n",
    "            total_time += t1 - t0\n",
    "      \n",
    "    score = np.array(score)\n",
    "    score = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\n",
    "    score = np.array([score[0]]*math.ceil((ts['slidingWindow']-1)/2) + list(score) + [score[-1]]*((ts['slidingWindow']-1)//2))\n",
    "\n",
    "    # Plot figure\n",
    "    #plotFig(ts['data'], ts['label'], scores, ts['global_sliding_window'], fileName=ts['name'] + ' ' + loaded_dict[ts['name']][0], modelName=modelName)\n",
    "\n",
    "    # Calculate the results\n",
    "    L = printResult(ts['data'], ts['label'], score, ts['slidingWindow'], ts['name'], modelName)\n",
    "    #L = [ '%.2f' % elem for elem in L]\n",
    "    #results.append([filename] + L)\n",
    "    results.append([filename] + L + [total_time, len(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['Filename'] + eval_metrics\n",
    "columns = ['Name'] + ['AUC', 'Precision', 'Recall', 'F-score', 'Range-recall', 'ExistenceReward', 'OverlapReward', 'Range-precision', 'Range-Fscore', 'Precision@k', 'RangeAUC', 'Time', 'Number of Windows']\n",
    "iforest_res = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Time</th>\n",
       "      <th>Number of Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG1</td>\n",
       "      <td>0.855992</td>\n",
       "      <td>0.142573</td>\n",
       "      <td>229.720105</td>\n",
       "      <td>229801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG1_20k</td>\n",
       "      <td>0.858151</td>\n",
       "      <td>0.314074</td>\n",
       "      <td>19.923992</td>\n",
       "      <td>19901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOPS1</td>\n",
       "      <td>0.506936</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>9.601570</td>\n",
       "      <td>8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMD1</td>\n",
       "      <td>0.367254</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>29.829531</td>\n",
       "      <td>28355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occupancy1</td>\n",
       "      <td>0.711537</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>2.683930</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECG1+IOPS1</td>\n",
       "      <td>0.675540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.455487</td>\n",
       "      <td>28685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMD1+Occupancy1</td>\n",
       "      <td>0.503673</td>\n",
       "      <td>0.031642</td>\n",
       "      <td>31.824658</td>\n",
       "      <td>31020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECG1+IOPS1+Occupancy1</td>\n",
       "      <td>0.758577</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>31.726269</td>\n",
       "      <td>31350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMD1+ECG1+Occupancy1</td>\n",
       "      <td>0.645449</td>\n",
       "      <td>0.032020</td>\n",
       "      <td>52.913753</td>\n",
       "      <td>51020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECG1+IOPS1+SMD1+Occupancy1</td>\n",
       "      <td>0.598401</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>61.405559</td>\n",
       "      <td>59829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name       AUC  Precision@k        Time  \\\n",
       "0                        ECG1  0.855992     0.142573  229.720105   \n",
       "1                    ECG1_20k  0.858151     0.314074   19.923992   \n",
       "2                       IOPS1  0.506936     0.004854    9.601570   \n",
       "3                        SMD1  0.367254     0.001856   29.829531   \n",
       "4                  Occupancy1  0.711537     0.064815    2.683930   \n",
       "5                  ECG1+IOPS1  0.675540     0.000000   29.455487   \n",
       "6             SMD1+Occupancy1  0.503673     0.031642   31.824658   \n",
       "7       ECG1+IOPS1+Occupancy1  0.758577     0.031840   31.726269   \n",
       "8        SMD1+ECG1+Occupancy1  0.645449     0.032020   52.913753   \n",
       "9  ECG1+IOPS1+SMD1+Occupancy1  0.598401     0.016494   61.405559   \n",
       "\n",
       "   Number of Windows  \n",
       "0             229801  \n",
       "1              19901  \n",
       "2               8497  \n",
       "3              28355  \n",
       "4               2541  \n",
       "5              28685  \n",
       "6              31020  \n",
       "7              31350  \n",
       "8              51020  \n",
       "9              59829  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_res['Number of anomalies'] = iforest_res['Name'].apply(lambda x: np.sum(preprocessed_dict[x]['label']))\n",
    "iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "                      Name &      AUC &  Precision@k &       Time &  Number of Windows \\\\\n",
      "\\midrule\n",
      "                      ECG1 & 0.855992 &     0.142573 & 229.720105 &             229801 \\\\\n",
      "                  ECG1\\_20k & 0.858151 &     0.314074 &  19.923992 &              19901 \\\\\n",
      "                     IOPS1 & 0.506936 &     0.004854 &   9.601570 &               8497 \\\\\n",
      "                      SMD1 & 0.367254 &     0.001856 &  29.829531 &              28355 \\\\\n",
      "                Occupancy1 & 0.711537 &     0.064815 &   2.683930 &               2541 \\\\\n",
      "                ECG1+IOPS1 & 0.675540 &     0.000000 &  29.455487 &              28685 \\\\\n",
      "           SMD1+Occupancy1 & 0.503673 &     0.031642 &  31.824658 &              31020 \\\\\n",
      "     ECG1+IOPS1+Occupancy1 & 0.758577 &     0.031840 &  31.726269 &              31350 \\\\\n",
      "      SMD1+ECG1+Occupancy1 & 0.645449 &     0.032020 &  52.913753 &              51020 \\\\\n",
      "ECG1+IOPS1+SMD1+Occupancy1 & 0.598401 &     0.016494 &  61.405559 &              59829 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Isolation Forest***(Variant 2)\n",
    "Streaming variant with batch history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'IForest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    scores = []\n",
    "    previous_scores = None\n",
    "    x = ts['X_data']\n",
    "    clf = IForest(n_jobs=7, random_state=42)\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, _ in enumerate(ts['batched_X_data']):\n",
    "        \n",
    "        if i == 0:\n",
    "            X_train = ts['batched_X_data'][i]\n",
    "        else:\n",
    "            X_train = np.concatenate((ts['batched_X_data'][i-1], ts['batched_X_data'][i]))\n",
    "        \n",
    "        t0 = time()\n",
    "        clf.fit(X_train)\n",
    "        score = clf.decision_scores_\n",
    "\n",
    "        if i > 0:\n",
    "            previous_partition_length = len(ts['batched_X_data'][i-1])\n",
    "            new_previous_scores = score[:previous_partition_length]\n",
    "            mean_previous_scores = (previous_scores + new_previous_scores) / 2\n",
    "            scores[-previous_partition_length:] = mean_previous_scores.tolist()\n",
    "\n",
    "        current_partition_length = len(ts['batched_X_data'][i])\n",
    "        current_scores = score[-current_partition_length:]\n",
    "        scores.extend(current_scores)\n",
    "\n",
    "        previous_scores = current_scores\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        total_time += t1 - t0\n",
    "    \n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    scores = MinMaxScaler(feature_range=(0, 1)).fit_transform(scores.reshape(-1, 1)).ravel()\n",
    "    scores = np.array([scores[0]] * math.ceil((ts['slidingWindow']-1)/2) +\n",
    "                         list(scores) +\n",
    "                         [scores[-1]] * ((ts['slidingWindow']-1)//2))\n",
    "    \n",
    "\n",
    "    # Plot figure\n",
    "    #plotFig(ts['data'], ts['label'], scores, ts['global_sliding_window'], fileName=ts['name'] + ' ' + loaded_dict[ts['name']][0], modelName=modelName)\n",
    "\n",
    "    # Calculate the results\n",
    "    L = printResult(ts['data'], ts['label'], scores, ts['slidingWindow'], ts['name'], modelName)\n",
    "    #L = [ '%.2f' % elem for elem in L]\n",
    "    #results.append([filename] + L)\n",
    "    results.append([filename] + L + [total_time, len(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['Filename'] + eval_metrics\n",
    "columns = ['Name'] + ['AUC', 'Precision', 'Recall', 'F-score', 'Range-recall', 'ExistenceReward', 'OverlapReward', 'Range-precision', 'Range-Fscore', 'Precision@k', 'RangeAUC', 'Time', 'Number of Windows']\n",
    "iforest_res = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Time</th>\n",
       "      <th>Number of Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG1</td>\n",
       "      <td>0.832550</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>246.065436</td>\n",
       "      <td>229801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG1_20k</td>\n",
       "      <td>0.831822</td>\n",
       "      <td>0.371852</td>\n",
       "      <td>21.628578</td>\n",
       "      <td>19901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOPS1</td>\n",
       "      <td>0.481980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.946975</td>\n",
       "      <td>8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMD1</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.679663</td>\n",
       "      <td>28355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occupancy1</td>\n",
       "      <td>0.763412</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>2.835710</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECG1+IOPS1</td>\n",
       "      <td>0.668095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.380143</td>\n",
       "      <td>28685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMD1+Occupancy1</td>\n",
       "      <td>0.478901</td>\n",
       "      <td>0.039825</td>\n",
       "      <td>34.411816</td>\n",
       "      <td>31020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECG1+IOPS1+Occupancy1</td>\n",
       "      <td>0.761818</td>\n",
       "      <td>0.031301</td>\n",
       "      <td>33.864426</td>\n",
       "      <td>31350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMD1+ECG1+Occupancy1</td>\n",
       "      <td>0.623556</td>\n",
       "      <td>0.041465</td>\n",
       "      <td>56.555439</td>\n",
       "      <td>51020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECG1+IOPS1+SMD1+Occupancy1</td>\n",
       "      <td>0.574619</td>\n",
       "      <td>0.017594</td>\n",
       "      <td>64.748370</td>\n",
       "      <td>59829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name       AUC  Precision@k        Time  \\\n",
       "0                        ECG1  0.832550     0.155556  246.065436   \n",
       "1                    ECG1_20k  0.831822     0.371852   21.628578   \n",
       "2                       IOPS1  0.481980     0.000000   10.946975   \n",
       "3                        SMD1  0.320700     0.000000   31.679663   \n",
       "4                  Occupancy1  0.763412     0.065844    2.835710   \n",
       "5                  ECG1+IOPS1  0.668095     0.000000   31.380143   \n",
       "6             SMD1+Occupancy1  0.478901     0.039825   34.411816   \n",
       "7       ECG1+IOPS1+Occupancy1  0.761818     0.031301   33.864426   \n",
       "8        SMD1+ECG1+Occupancy1  0.623556     0.041465   56.555439   \n",
       "9  ECG1+IOPS1+SMD1+Occupancy1  0.574619     0.017594   64.748370   \n",
       "\n",
       "   Number of Windows  \n",
       "0             229801  \n",
       "1              19901  \n",
       "2               8497  \n",
       "3              28355  \n",
       "4               2541  \n",
       "5              28685  \n",
       "6              31020  \n",
       "7              31350  \n",
       "8              51020  \n",
       "9              59829  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_res['Number of anomalies'] = iforest_res['Name'].apply(lambda x: np.sum(preprocessed_dict[x]['label']))\n",
    "iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "                      Name &      AUC &  Precision@k &       Time &  Number of Windows \\\\\n",
      "\\midrule\n",
      "                      ECG1 & 0.832550 &     0.155556 & 246.065436 &             229801 \\\\\n",
      "                  ECG1\\_20k & 0.831822 &     0.371852 &  21.628578 &              19901 \\\\\n",
      "                     IOPS1 & 0.481980 &     0.000000 &  10.946975 &               8497 \\\\\n",
      "                      SMD1 & 0.320700 &     0.000000 &  31.679663 &              28355 \\\\\n",
      "                Occupancy1 & 0.763412 &     0.065844 &   2.835710 &               2541 \\\\\n",
      "                ECG1+IOPS1 & 0.668095 &     0.000000 &  31.380143 &              28685 \\\\\n",
      "           SMD1+Occupancy1 & 0.478901 &     0.039825 &  34.411816 &              31020 \\\\\n",
      "     ECG1+IOPS1+Occupancy1 & 0.761818 &     0.031301 &  33.864426 &              31350 \\\\\n",
      "      SMD1+ECG1+Occupancy1 & 0.623556 &     0.041465 &  56.555439 &              51020 \\\\\n",
      "ECG1+IOPS1+SMD1+Occupancy1 & 0.574619 &     0.017594 &  64.748370 &              59829 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Isolation Forest***(Variant 3)\n",
    "Dynamic partitioning and classification based on ensemblers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'IForest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the last p points of the previous partition with both classifiers and replaces scores if they disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "clf = IForest(n_jobs=7, random_state=42)\n",
    "for filename in preprocessed_dict.keys():\n",
    "    ts = preprocessed_dict[filename]\n",
    "    window_size = ts['global_sliding_window']\n",
    "    x = ts['data']\n",
    "    \n",
    "    k = 1\n",
    "    score = []\n",
    "    t0 = time()\n",
    "    for i, batch in enumerate(ts['data partitions']):\n",
    "        \n",
    "        # If there are not enough points to do at least a window, pad with the last score.\n",
    "        if len(batch) < window_size:\n",
    "            score_ = [score[-1]] * len(batch)\n",
    "        else:\n",
    "            X_train = Window(window=window_size).convert(batch).to_numpy()\n",
    "            clf.fit(X_train)\n",
    "            score_ = clf.decision_scores_\n",
    "\n",
    "            # Because batches are being split in a way that doesn't allow windows to cross batch boundaries, pad predictions to account for lost\n",
    "            # windows.\n",
    "            score_ = np.array([score_[0]]*math.ceil((ts['global_sliding_window']-1)/2) + list(score_) + [score_[-1]]*((ts['global_sliding_window']-1)//2))\n",
    "\n",
    "        score.extend(score_)\n",
    "    t1 = time()\n",
    "\n",
    "    # In some combinations of batch size and window size, windows overlap with all closest-distance candidates and cannot be scored.\n",
    "    # In this case, inf is returned. To fix this, any instances of infinite distances are replaced with zero distance.\n",
    "    score = [s if s != np.inf else 0 for s in score]\n",
    "    score = np.array(score)\n",
    "    score = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\n",
    "    # score = np.array([score[0]]*math.ceil((ts['slidingWindow']-1)/2) + list(score) + [score[-1]]*((ts['slidingWindow']-1)//2))\n",
    "    \n",
    "    L = printResult(ts['data'], ts['label'], score, ts['global_sliding_window'], ts['name'], modelName)\n",
    "    results.append([filename] + L + [t1-t0, len(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['Filename'] + eval_metrics\n",
    "columns = ['Name'] + ['AUC', 'Precision', 'Recall', 'F-score', 'Range-recall', 'ExistenceReward', 'OverlapReward', 'Range-precision', 'Range-Fscore', 'Precision@k', 'RangeAUC', 'Time', 'Number of Windows']\n",
    "iforest_res = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Time</th>\n",
       "      <th>Number of Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG1</td>\n",
       "      <td>0.814735</td>\n",
       "      <td>0.135513</td>\n",
       "      <td>74.870748</td>\n",
       "      <td>229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG1_20k</td>\n",
       "      <td>0.776898</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>6.752509</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOPS1</td>\n",
       "      <td>0.530030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.232990</td>\n",
       "      <td>8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMD1</td>\n",
       "      <td>0.492151</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>8.748321</td>\n",
       "      <td>28479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occupancy1</td>\n",
       "      <td>0.780974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767657</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECG1+IOPS1</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.719672</td>\n",
       "      <td>28784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMD1+Occupancy1</td>\n",
       "      <td>0.595549</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>9.573527</td>\n",
       "      <td>31144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECG1+IOPS1+Occupancy1</td>\n",
       "      <td>0.767134</td>\n",
       "      <td>0.081489</td>\n",
       "      <td>10.324798</td>\n",
       "      <td>31449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMD1+ECG1+Occupancy1</td>\n",
       "      <td>0.688721</td>\n",
       "      <td>0.058051</td>\n",
       "      <td>16.063449</td>\n",
       "      <td>51144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECG1+IOPS1+SMD1+Occupancy1</td>\n",
       "      <td>0.624106</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>19.405434</td>\n",
       "      <td>59928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name       AUC  Precision@k       Time  \\\n",
       "0                        ECG1  0.814735     0.135513  74.870748   \n",
       "1                    ECG1_20k  0.776898     0.320000   6.752509   \n",
       "2                       IOPS1  0.530030     0.000000   3.232990   \n",
       "3                        SMD1  0.492151     0.024128   8.748321   \n",
       "4                  Occupancy1  0.780974     0.000000   0.767657   \n",
       "5                  ECG1+IOPS1  0.652917     0.000000   9.719672   \n",
       "6             SMD1+Occupancy1  0.595549     0.069831   9.573527   \n",
       "7       ECG1+IOPS1+Occupancy1  0.767134     0.081489  10.324798   \n",
       "8        SMD1+ECG1+Occupancy1  0.688721     0.058051  16.063449   \n",
       "9  ECG1+IOPS1+SMD1+Occupancy1  0.624106     0.022872  19.405434   \n",
       "\n",
       "   Number of Windows  \n",
       "0             229900  \n",
       "1              20000  \n",
       "2               8784  \n",
       "3              28479  \n",
       "4               2665  \n",
       "5              28784  \n",
       "6              31144  \n",
       "7              31449  \n",
       "8              51144  \n",
       "9              59928  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_res['Number of anomalies'] = iforest_res['Name'].apply(lambda x: np.sum(preprocessed_dict[x]['label']))\n",
    "iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "                      Name &      AUC &  Precision@k &      Time &  Number of Windows \\\\\n",
      "\\midrule\n",
      "                      ECG1 & 0.814735 &     0.135513 & 74.870748 &             229900 \\\\\n",
      "                  ECG1\\_20k & 0.776898 &     0.320000 &  6.752509 &              20000 \\\\\n",
      "                     IOPS1 & 0.530030 &     0.000000 &  3.232990 &               8784 \\\\\n",
      "                      SMD1 & 0.492151 &     0.024128 &  8.748321 &              28479 \\\\\n",
      "                Occupancy1 & 0.780974 &     0.000000 &  0.767657 &               2665 \\\\\n",
      "                ECG1+IOPS1 & 0.652917 &     0.000000 &  9.719672 &              28784 \\\\\n",
      "           SMD1+Occupancy1 & 0.595549 &     0.069831 &  9.573527 &              31144 \\\\\n",
      "     ECG1+IOPS1+Occupancy1 & 0.767134 &     0.081489 & 10.324798 &              31449 \\\\\n",
      "      SMD1+ECG1+Occupancy1 & 0.688721 &     0.058051 & 16.063449 &              51144 \\\\\n",
      "ECG1+IOPS1+SMD1+Occupancy1 & 0.624106 &     0.022872 & 19.405434 &              59928 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Isolation Forest***(Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for the evaluation.\n",
    "all_data = []\n",
    "\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "all_data.extend(data['evaluation']['single_normality'])\n",
    "all_data.extend(data['evaluation']['double_normality'])\n",
    "all_data.extend(data['evaluation']['triple_normality'])\n",
    "all_data.extend(data['evaluation']['quadruple_normality'])\n",
    "name_to_eval_series = {ts['Name']:ts for ts in all_data}\n",
    "\n",
    "tuning_data = []\n",
    "tuning_data.extend(data['tuning']['single_normality'])\n",
    "tuning_data.extend(data['tuning']['double_normality'])\n",
    "tuning_data.extend(data['tuning']['triple_normality'])\n",
    "tuning_data.extend(data['tuning']['quadruple_normality'])\n",
    "name_to_tune_series = {ts['Name']:ts for ts in tuning_data}\n",
    "\n",
    "# Set the number of windows to be fit per batch.\n",
    "windows_per_batch = 150\n",
    "\n",
    "def preprocess_series(series, slidingWindow=None, verbose=True):\n",
    "    name = timeseries['Name']\n",
    "\n",
    "    data = timeseries['data']\n",
    "    max_length = data.shape[0]\n",
    "    label = timeseries['labels']\n",
    "\n",
    "    if slidingWindow is None:\n",
    "        slidingWindow = find_length(data)\n",
    "    X_data = Window(window=slidingWindow).convert(data).to_numpy()\n",
    "\n",
    "    # Take the series and batch it.\n",
    "    batched_data = []\n",
    "\n",
    "    i = 0\n",
    "    flag = True\n",
    "    # Keep taking batches until the point at which no new windows can be taken.\n",
    "    while i < len(data) and flag:\n",
    "        # The data batches begin at the index indicated. If first batch, then the beginning of the time series.\n",
    "        batch_samples_begin = i\n",
    "\n",
    "        # The data batches end at the index where `windows_per_batch` can be *completely* extracted since the batch beginning. \n",
    "        # Formula: \n",
    "        #   i: current beginning of batch / offset\n",
    "        #   + slidingWindow: to have enough samples extract one window\n",
    "        #   + windows_per_batch: to have enough samples to extract the rest of the windows\n",
    "        #   - 1: because the first window extracted is counted twice\n",
    "        batch_samples_end = i + windows_per_batch + slidingWindow - 1\n",
    "        \n",
    "        # Guard against the ending of the time series where a full batch cannot be formed.\n",
    "        if batch_samples_end > len(data):\n",
    "            batch_samples_end = len(data)\n",
    "            flag = False\n",
    " \n",
    "        # Guard against case where the batch cannot hold even one window.\n",
    "        if len(data[batch_samples_begin:batch_samples_end]) < slidingWindow:\n",
    "            break\n",
    "\n",
    "        batched_data.append(data[batch_samples_begin:batch_samples_end])\n",
    "\n",
    "        # The next batch starts at the point where a new window be created after the last window of the last batch.\n",
    "        # So, end of the previous window - length of window = start of the last window.\n",
    "        #   start of the last window + 1 = start of the first window of the next batch.\n",
    "        i = batch_samples_end - slidingWindow + 1\n",
    "\n",
    "\n",
    "    # Take the windows and batch them.\n",
    "    batched_X_data = []\n",
    "    i = 0\n",
    "    while i < len(X_data):\n",
    "        begin = i\n",
    "        end = i + windows_per_batch\n",
    "        if end > len(X_data):\n",
    "            end = len(X_data)\n",
    "\n",
    "        batched_X_data.append(X_data[begin:end])\n",
    "        i += windows_per_batch\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Time-Series name: {name}')\n",
    "        print(\"Estimated Subsequence length: \", slidingWindow)\n",
    "        print()\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'data': data,\n",
    "        'label': label,\n",
    "        'slidingWindow': slidingWindow,\n",
    "        'X_data': X_data,\n",
    "        'batched_X_data': batched_X_data,\n",
    "        'batched_data': batched_data,\n",
    "        'Time series length': len(data),\n",
    "        'Number of abnormal points': list(label).count(1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]ECG2  --  Best AUC = 0.7419731328320758 for: (1.0, 100)\n",
      "ECG2  --  Best AUC = 0.7419731328320758 for: (1.0, 100)\n",
      "ECG1  --  Eval AUC = 0.7419731328320758\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]ECG2_20k  --  Best AUC = 0.7202198089139109 for: (1.0, 100)\n",
      "ECG2_20k  --  Best AUC = 0.7202198089139109 for: (1.0, 100)\n",
      "ECG1_20k  --  Eval AUC = 0.7202198089139109\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]IOPS2  --  Best AUC = 0.3884730569214269 for: (1.0, 100)\n",
      "IOPS2  --  Best AUC = 0.3884730569214269 for: (1.0, 100)\n",
      "IOPS1  --  Eval AUC = 0.3884730569214269\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]SMD2  --  Best AUC = 0.22131571980567422 for: (1.0, 100)\n",
      "SMD2  --  Best AUC = 0.22131571980567422 for: (1.0, 100)\n",
      "SMD1  --  Eval AUC = 0.22131571980567422\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]Occupancy2  --  Best AUC = 0.7555554340190423 for: (1.0, 100)\n",
      "Occupancy2  --  Best AUC = 0.7555554340190423 for: (1.0, 100)\n",
      "Occupancy1  --  Eval AUC = 0.7555554340190423\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]ECG2+IOPS2  --  Best AUC = 0.5458670782804637 for: (1.0, 100)\n",
      "ECG2+IOPS2  --  Best AUC = 0.5458670782804637 for: (1.0, 100)\n",
      "ECG1+IOPS1  --  Eval AUC = 0.5458670782804637\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]SMD2+Occupancy2  --  Best AUC = 0.4102527868647147 for: (1.0, 100)\n",
      "SMD2+Occupancy2  --  Best AUC = 0.4102527868647147 for: (1.0, 100)\n",
      "SMD1+Occupancy1  --  Eval AUC = 0.4102527868647147\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]ECG2+IOPS2+Occupancy2  --  Best AUC = 0.6582851632487368 for: (1.0, 100)\n",
      "ECG2+IOPS2+Occupancy2  --  Best AUC = 0.6582851632487368 for: (1.0, 100)\n",
      "ECG1+IOPS1+Occupancy1  --  Eval AUC = 0.6582851632487368\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]SMD2+ECG2+Occupancy2  --  Best AUC = 0.5003444308147326 for: (1.0, 100)\n",
      "SMD2+ECG2+Occupancy2  --  Best AUC = 0.5003444308147326 for: (1.0, 100)\n",
      "SMD1+ECG1+Occupancy1  --  Eval AUC = 0.5003444308147326\n",
      "\n",
      "----------------------------------------------------------------\n",
      "[1/1]ECG2+IOPS2+SMD2+Occupancy2  --  Best AUC = 0.47659086313136545 for: (1.0, 100)\n",
      "ECG2+IOPS2+SMD2+Occupancy2  --  Best AUC = 0.47659086313136545 for: (1.0, 100)\n",
      "ECG1+IOPS1+SMD1+Occupancy1  --  Eval AUC = 0.47659086313136545\n",
      "\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "results = []\n",
    "\n",
    "# Parameters for tuning.\n",
    "param_grid = {\n",
    "    # Using the estimated window length from the autocorrelation, define alternate window sized as fractions/multiples of that.\n",
    "    #'window_length_modifier': [0.5, 1.0, 2.0], \n",
    "    'window_length_modifier': [1.0],\n",
    "    # Number of trees in the isolation forest.\n",
    "    #'n_estimators': [50, 100, 200],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "params_to_AUC = defaultdict(dict)\n",
    "\n",
    "total = np.product([len(pl) for pl in param_grid.values()])\n",
    "\n",
    "for timeseries in tuning_data:\n",
    "    name = timeseries['Name']\n",
    "\n",
    "    default_sliding_window = find_length(timeseries['data'])\n",
    "    \n",
    "    c = 0\n",
    "    best_AUC = 0\n",
    "    # Initial Best parameters are the defaults.\n",
    "    best_params = (1, 100)\n",
    "    for window_length_modifier in param_grid['window_length_modifier']:\n",
    "        for n_estimators in param_grid['n_estimators']:\n",
    "            # Prevent too small windows.\n",
    "            window_size = max(10, int(window_length_modifier * default_sliding_window))\n",
    "\n",
    "            ts = preprocess_series(series=timeseries, verbose=False)\n",
    "\n",
    "            x = ts['X_data']\n",
    "            clf = IForest(n_jobs=7, random_state=42, n_estimators=n_estimators)\n",
    "            total_time = 0\n",
    "            scores = []\n",
    "\n",
    "            for i, _ in enumerate(ts['batched_X_data']):\n",
    "                \n",
    "                if i == 0:\n",
    "                    X_train = ts['batched_X_data'][i]\n",
    "                else:\n",
    "                    X_train = np.concatenate((ts['batched_X_data'][i-1], ts['batched_X_data'][i]))\n",
    "                \n",
    "                t0 = time()\n",
    "                clf.fit(X_train)\n",
    "                score = clf.decision_scores_\n",
    "\n",
    "                if i > 0:\n",
    "                    previous_partition_length = len(ts['batched_X_data'][i-1])\n",
    "                    new_previous_scores = score[:previous_partition_length]\n",
    "                    mean_previous_scores = (previous_scores + new_previous_scores) / 2\n",
    "                    scores[-previous_partition_length:] = mean_previous_scores.tolist()\n",
    "\n",
    "                current_partition_length = len(ts['batched_X_data'][i])\n",
    "                current_scores = score[-current_partition_length:]\n",
    "                scores.extend(current_scores)\n",
    "\n",
    "                previous_scores = current_scores\n",
    "\n",
    "                t1 = time()\n",
    "\n",
    "                total_time += t1 - t0\n",
    "\n",
    "            score = np.array(scores)\n",
    "            score = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\n",
    "            score = np.array([score[0]]*math.ceil((ts['slidingWindow']-1)/2) + list(score) + [score[-1]]*((ts['slidingWindow']-1)//2))\n",
    "            \n",
    "            AUC = printResult(ts['data'], ts['label'], score, window_size, ts['name'], modelName)[0]\n",
    "\n",
    "            params_to_AUC[name][(window_length_modifier, n_estimators)] = AUC\n",
    "\n",
    "            if AUC > best_AUC:\n",
    "                best_AUC = AUC\n",
    "                best_params = (window_length_modifier, n_estimators)\n",
    "\n",
    "            c+=1\n",
    "            print(f\"\\r[{c}/{total}]{name}  --  Best AUC = {best_AUC} for: {best_params}\", end='')\n",
    "    print()\n",
    "    print(f\"{name}  --  Best AUC = {best_AUC} for: {best_params}\")\n",
    "\n",
    "    # Evaluate evaluation time series with selected parameters.    \n",
    "    window_size = max(10, int(ts['slidingWindow'] * best_params[0]))\n",
    "    n_estimators = best_params[1]\n",
    "\n",
    "    eval_series_name = ''.join([n if n!='2' else '1' for n in name]).replace('10k', '20k')  # Replace 2s with 1s and fix 20k becoming 10k accidentally.\n",
    "    ts = preprocess_series(series=timeseries, slidingWindow=window_size, verbose=False)\n",
    "\n",
    "    x = ts['X_data']\n",
    "    clf = IForest(n_jobs=10, random_state=42, n_estimators=n_estimators)\n",
    "    total_time = 0\n",
    "    scores = []\n",
    "\n",
    "    for i, _ in enumerate(ts['batched_X_data']):\n",
    "        \n",
    "        if i == 0:\n",
    "            X_train = ts['batched_X_data'][i]\n",
    "        else:\n",
    "            X_train = np.concatenate((ts['batched_X_data'][i-1], ts['batched_X_data'][i]))\n",
    "        \n",
    "        t0 = time()\n",
    "        clf.fit(X_train)\n",
    "        score = clf.decision_scores_\n",
    "\n",
    "        if i > 0:\n",
    "            previous_partition_length = len(ts['batched_X_data'][i-1])\n",
    "            new_previous_scores = score[:previous_partition_length]\n",
    "            mean_previous_scores = (previous_scores + new_previous_scores) / 2\n",
    "            scores[-previous_partition_length:] = mean_previous_scores.tolist()\n",
    "\n",
    "        current_partition_length = len(ts['batched_X_data'][i])\n",
    "        current_scores = score[-current_partition_length:]\n",
    "        scores.extend(current_scores)\n",
    "\n",
    "        previous_scores = current_scores\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        total_time += t1 - t0\n",
    "\n",
    "    score = np.array(scores)\n",
    "    score = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\n",
    "    score = np.array([score[0]]*math.ceil((ts['slidingWindow']-1)/2) + list(score) + [score[-1]]*((ts['slidingWindow']-1)//2))\n",
    "    \n",
    "    L = printResult(ts['data'], ts['label'], score, window_size, ts['name'], modelName)\n",
    "    print(f\"{eval_series_name}  --  Eval AUC = {L[0]}\")\n",
    "    results.append([name] + L + [t1-t0, len(x)])\n",
    "\n",
    "    print()\n",
    "    print('----------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['Filename'] + eval_metrics\n",
    "columns = ['Name'] + ['AUC', 'Precision', 'Recall', 'F-score', 'Range-recall', 'ExistenceReward', 'OverlapReward', 'Range-precision', 'Range-Fscore', 'Precision@k', 'RangeAUC', 'Time', 'Number of Windows']\n",
    "iforest_res = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Range-recall</th>\n",
       "      <th>ExistenceReward</th>\n",
       "      <th>OverlapReward</th>\n",
       "      <th>Range-precision</th>\n",
       "      <th>Range-Fscore</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>RangeAUC</th>\n",
       "      <th>Time</th>\n",
       "      <th>Number of Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG2</td>\n",
       "      <td>0.741973</td>\n",
       "      <td>0.827669</td>\n",
       "      <td>0.094139</td>\n",
       "      <td>0.169050</td>\n",
       "      <td>0.074426</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>0.768221</td>\n",
       "      <td>0.135705</td>\n",
       "      <td>0.094139</td>\n",
       "      <td>0.822504</td>\n",
       "      <td>0.150624</td>\n",
       "      <td>229812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECG2_20k</td>\n",
       "      <td>0.720220</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.136006</td>\n",
       "      <td>0.227409</td>\n",
       "      <td>0.141547</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.065822</td>\n",
       "      <td>0.504284</td>\n",
       "      <td>0.221048</td>\n",
       "      <td>0.136006</td>\n",
       "      <td>0.794067</td>\n",
       "      <td>0.165808</td>\n",
       "      <td>19912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOPS2</td>\n",
       "      <td>0.388473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.185493</td>\n",
       "      <td>8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMD2</td>\n",
       "      <td>0.221316</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.036933</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.217048</td>\n",
       "      <td>0.159643</td>\n",
       "      <td>28355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occupancy2</td>\n",
       "      <td>0.755555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.826117</td>\n",
       "      <td>0.169454</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECG2+IOPS2</td>\n",
       "      <td>0.545867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810079</td>\n",
       "      <td>0.159625</td>\n",
       "      <td>28696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMD2+Occupancy2</td>\n",
       "      <td>0.410253</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.064921</td>\n",
       "      <td>0.118653</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.068771</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.202228</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.403234</td>\n",
       "      <td>0.161463</td>\n",
       "      <td>31020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECG2+IOPS2+Occupancy2</td>\n",
       "      <td>0.658285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809885</td>\n",
       "      <td>0.157182</td>\n",
       "      <td>31361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMD2+ECG2+Occupancy2</td>\n",
       "      <td>0.500344</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.038712</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.092183</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.058979</td>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.160986</td>\n",
       "      <td>0.038712</td>\n",
       "      <td>0.526714</td>\n",
       "      <td>0.161667</td>\n",
       "      <td>51020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECG2+IOPS2+SMD2+Occupancy2</td>\n",
       "      <td>0.476591</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.629179</td>\n",
       "      <td>0.170277</td>\n",
       "      <td>59840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name       AUC  Precision    Recall   F-score  \\\n",
       "0                        ECG2  0.741973   0.827669  0.094139  0.169050   \n",
       "1                    ECG2_20k  0.720220   0.693431  0.136006  0.227409   \n",
       "2                       IOPS2  0.388473   0.000000  0.000000  0.000000   \n",
       "3                        SMD2  0.221316   0.103448  0.001114  0.002203   \n",
       "4                  Occupancy2  0.755555   1.000000  0.065844  0.123552   \n",
       "5                  ECG2+IOPS2  0.545867   0.000000  0.000000  0.000000   \n",
       "6             SMD2+Occupancy2  0.410253   0.805195  0.033824  0.064921   \n",
       "7       ECG2+IOPS2+Occupancy2  0.658285   0.000000  0.000000  0.000000   \n",
       "8        SMD2+ECG2+Occupancy2  0.500344   0.700000  0.038712  0.073367   \n",
       "9  ECG2+IOPS2+SMD2+Occupancy2  0.476591   0.588235  0.001932  0.003851   \n",
       "\n",
       "   Range-recall  ExistenceReward  OverlapReward  Range-precision  \\\n",
       "0      0.074426         0.268456       0.025919         0.768221   \n",
       "1      0.141547         0.444444       0.065822         0.504284   \n",
       "2      0.000000         0.000000       0.000000         0.000000   \n",
       "3      0.025542         0.125000       0.000677         0.066667   \n",
       "4      0.033040         0.071429       0.023443         1.000000   \n",
       "5      0.000000         0.000000       0.000000         0.000000   \n",
       "6      0.118653         0.318182       0.068771         0.684028   \n",
       "7      0.000000         0.000000       0.000000         0.000000   \n",
       "8      0.092183         0.225000       0.058979         0.634734   \n",
       "9      0.012341         0.046154       0.003888         0.380952   \n",
       "\n",
       "   Range-Fscore  Precision@k  RangeAUC      Time  Number of Windows  \n",
       "0      0.135705     0.094139  0.822504  0.150624             229812  \n",
       "1      0.221048     0.136006  0.794067  0.165808              19912  \n",
       "2      0.000000     0.000000  0.732412  0.185493               8497  \n",
       "3      0.036933     0.001114  0.217048  0.159643              28355  \n",
       "4      0.063967     0.065844  0.826117  0.169454               2541  \n",
       "5      0.000000     0.000000  0.810079  0.159625              28696  \n",
       "6      0.202228     0.033824  0.403234  0.161463              31020  \n",
       "7      0.000000     0.000000  0.809885  0.157182              31361  \n",
       "8      0.160986     0.038712  0.526714  0.161667              51020  \n",
       "9      0.023908     0.001932  0.629179  0.170277              59840  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_res['Number of anomalies'] = iforest_res['Name'].apply(lambda x: np.sum(name_to_eval_series[x]['labels']))\n",
    "iforest_res[['Name', 'AUC', 'Precision@k', 'Number of anomalies', 'Time', 'Number of Windows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iforest_res[['Name', 'AUC', 'Precision@k', 'Time', 'Number of Windows']].to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
